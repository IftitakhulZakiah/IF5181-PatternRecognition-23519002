{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19909 27\n"
     ]
    }
   ],
   "source": [
    "data = open('dinos.txt', 'r').read()\n",
    "data = data.lower()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(data_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = {ch:i for i,ch in enumerate(sorted(chars))}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(sorted(chars))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(gradients, maxValue):\n",
    "    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients['dby']\n",
    "    \n",
    "    for gradient in [dWax, dWaa, dWya, db, dby]:\n",
    "        np.clip(gradient, -maxValue, maxValue, gradient)\n",
    "        \n",
    "    gradients = {'dWaa': dWaa, 'dWax': dWax, 'dWya': dWya, 'db': db, 'dby':dby}\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "-10.0\n",
      "0.2971381536101662\n",
      "[10.]\n",
      "[8.45833407]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "dWax = np.random.randn(5,3)*10\n",
    "dWaa = np.random.randn(5,5)*10\n",
    "dWya = np.random.randn(2,5)*10\n",
    "db = np.random.randn(5,1)*10\n",
    "dby = np.random.randn(2,1)*10\n",
    "\n",
    "gradients = {'dWaa': dWaa, 'dWax': dWax, 'dWya': dWya, 'db': db, 'dby':dby}\n",
    "gradients = clip(gradients, 10)\n",
    "print(gradients['dWaa'][1][2])\n",
    "print(gradients['dWax'][3][1])\n",
    "print(gradients['dWya'][1][2])\n",
    "print(gradients['db'][4])\n",
    "print(gradients['dby'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, seed):\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    vocab_size = by.shape[0]\n",
    "    n_a = Waa.shape[1]\n",
    "    n_x = Wax.shape[1]\n",
    "    \n",
    "    x = np.zeros((n_x, 1))\n",
    "    a_prev = np.zeros((n_a, 1))\n",
    "    \n",
    "    indices = []\n",
    "    \n",
    "    idx = -1\n",
    "    counter = 0\n",
    "    newline_char = char_to_ix['\\n']\n",
    "    while(idx != newline_char and counter != 50):\n",
    "        a = np.tanh(np.dot(Wax,x)+np.dot(Waa,a_prev)+b)\n",
    "        z = np.dot(Wya,a) + by\n",
    "        y = softmax(z)\n",
    "        \n",
    "        np.random.randn(counter+seed)\n",
    "        \n",
    "        idx = np.random.choice(range(0, vocab_size), p=y.ravel())\n",
    "        \n",
    "        indices.append(idx)\n",
    "        \n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[idx] = 1\n",
    "        \n",
    "        a_prev = a\n",
    "        seed += 1\n",
    "        counter += 1\n",
    "        \n",
    "    if(counter==50):\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "        \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 17, 17, 1, 14, 12, 10, 19, 24, 6, 12, 13, 9, 7, 6, 25, 17, 23, 22, 5, 15, 17, 23, 24, 17, 22, 12, 0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "_, n_a = 20,100\n",
    "\n",
    "Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)\n",
    "b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)\n",
    "parameters = {'Wax': Wax, 'Waa': Waa, 'Wya': Wya, 'b': b, 'by': by}\n",
    "\n",
    "indices = sample(parameters, char_to_ix, 0)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters, learning_rate=0.01):\n",
    "    loss, cache = rnn_forward(X, Y, a_prev, parameters)\n",
    "    gradients, a = rnn_backward(X, Y, parameters, cache)\n",
    "    gradients = clip(gradients, 5)\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "    \n",
    "    return loss, gradients, a[len(X)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.50397572165362\n",
      "0.19470931534720892\n",
      "93\n",
      "-0.007773876032003782\n",
      "[-0.06809825]\n",
      "[0.01538192]\n",
      "[-1.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "vocab_size, n_a = 27,100\n",
    "a_prev = np.random.randn(n_a,1)\n",
    "Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)\n",
    "b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)\n",
    "parameters = {'Wax': Wax, 'Waa': Waa, 'Wya': Wya, 'b': b, 'by': by}\n",
    "X = [12,3,5,11,22,3]\n",
    "Y = [4,14,11,22,25,26]\n",
    "\n",
    "loss, gradients, a_last = optimize(X, Y, a_prev, parameters, learning_rate=0.01)\n",
    "print(loss)\n",
    "print(gradients['dWaa'][1][2])\n",
    "print(np.argmax(gradients['dWax']))\n",
    "print(gradients['dWya'][1][2])\n",
    "print(gradients['db'][4])\n",
    "print(gradients['dby'][1])\n",
    "print(a_last[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, ix_to_char, char_to_ix, num_iterations=35000, n_a=50, dino_names=7, vocab_size=27):\n",
    "    n_x, n_y = vocab_size, vocab_size\n",
    "    \n",
    "    parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "    \n",
    "    loss = get_initial_loss(vocab_size, dino_names)\n",
    "    \n",
    "    with open('dinos.txt') as f:\n",
    "        examples = f.readlines()\n",
    "    examples = [x.lower().strip() for x in examples]\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(examples)\n",
    "    \n",
    "    a_prev = np.zeros((n_a, 1))\n",
    "    \n",
    "    for j in range(num_iterations):\n",
    "        index = j % len(examples)\n",
    "        X = [None] + [char_to_ix[ch] for ch in examples[index]]\n",
    "        Y = X[1:] + [char_to_ix['\\n']]\n",
    "        \n",
    "        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate=0.01)\n",
    "        \n",
    "        if j % 2000 == 0:\n",
    "            print('Iteration: %d, Loss: %f' %(j, loss) + '\\n')\n",
    "            seed = 0\n",
    "            for name in range(dino_names):\n",
    "                sampled_indices = sample(parameters, char_to_ix, seed)\n",
    "                print_sample(sampled_indices, ix_to_char)\n",
    "                seed += 1\n",
    "            print('\\n')\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 23.070858\n",
      "\n",
      "Cgestojczq\n",
      "Dka\n",
      "Wrngnritumochjwvtve\n",
      "Lwras\n",
      "Djmkafcjdsu\n",
      "Quxxnvuzfc\n",
      "Gkoo\n",
      "\n",
      "\n",
      "Iteration: 2000, Loss: 23.070858\n",
      "\n",
      "Mippgorhuirus\n",
      "Isauzos\n",
      "Waonysaurus\n",
      "Pkusaurus\n",
      "Muauscerosaurus\n",
      "Saurus\n",
      "Aurudetgipefbmaalos\n",
      "\n",
      "\n",
      "Iteration: 4000, Loss: 23.070858\n",
      "\n",
      "Eyhinisakrnianos\n",
      "Eglasaurus\n",
      "Lutosavous\n",
      "Ulirakosaurus\n",
      "Oreus\n",
      "Tmor\n",
      "Spstrosaurus\n",
      "\n",
      "\n",
      "Iteration: 6000, Loss: 23.070858\n",
      "\n",
      "Mproson\n",
      "Mherocen\n",
      "Elaeosaurus\n",
      "Losaustes\n",
      "Eodelodon\n",
      "Pnoceopamapor\n",
      "Zekosaurus\n",
      "\n",
      "\n",
      "Iteration: 8000, Loss: 23.070858\n",
      "\n",
      "Lisichus\n",
      "Raptosaurus\n",
      "Saurlateragops\n",
      "Rebboocoras\n",
      "Rongtodenstosaurus\n",
      "Terlatops\n",
      "Itosirrangonocelatops\n",
      "\n",
      "\n",
      "Iteration: 10000, Loss: 23.070858\n",
      "\n",
      "Nolechus\n",
      "Uitia\n",
      "Dheria\n",
      "Arrootos\n",
      "Atataosaurus\n",
      "Flohusaurus\n",
      "Otocona\n",
      "\n",
      "\n",
      "Iteration: 12000, Loss: 23.070858\n",
      "\n",
      "Zspnoseethomasaurucurayhon\n",
      "Enlang\n",
      "Gaknishus\n",
      "Kecsosaurus\n",
      "Uxelossratlangapdontedphodes\n",
      "Cophanosaurus\n",
      "Eeasaurus\n",
      "\n",
      "\n",
      "Iteration: 14000, Loss: 23.070858\n",
      "\n",
      "Thmosaurus\n",
      "Qinototdesaurus\n",
      "Sicosaur\n",
      "Troteosaurus\n",
      "Traloptilosius\n",
      "Muricierosaurus\n",
      "Loryove\n",
      "\n",
      "\n",
      "Iteration: 16000, Loss: 23.070858\n",
      "\n",
      "Walodon\n",
      "Ylutinos\n",
      "Krhyzaxbhasiaorus\n",
      "Nturiodon\n",
      "Antayosaurus\n",
      "Ancilapdacis\n",
      "Pastatia\n",
      "\n",
      "\n",
      "Iteration: 18000, Loss: 23.070858\n",
      "\n",
      "Pros\n",
      "Elancus\n",
      "Stornovona\n",
      "Orchenosaurue\n",
      "Verrysaurus\n",
      "Tangtitho\n",
      "Salraosaurus\n",
      "\n",
      "\n",
      "Iteration: 20000, Loss: 23.070858\n",
      "\n",
      "Nteorosaurus\n",
      "Verhychusgretosucoterisaurus\n",
      "Lurisaurus\n",
      "Coronganosaurus\n",
      "Panonegosaurus\n",
      "Torhusaurus\n",
      "Losibhonesaurus\n",
      "\n",
      "\n",
      "Iteration: 22000, Loss: 23.070858\n",
      "\n",
      "Nethoceratops\n",
      "Psorkephoros\n",
      "Utonotonyxijtotatosaurus\n",
      "Kriphosaurus\n",
      "Jyras\n",
      "Celnacorak\n",
      "Ptarria\n",
      "\n",
      "\n",
      "Iteration: 24000, Loss: 23.070858\n",
      "\n",
      "Trasaurus\n",
      "Telilevenaceratops\n",
      "Recsania\n",
      "Chunosaurue\n",
      "Aprophoteosaurus\n",
      "Gnoranthracodbn\n",
      "Teegnaptitanteu\n",
      "\n",
      "\n",
      "Iteration: 26000, Loss: 23.070858\n",
      "\n",
      "Krauaniodenthon\n",
      "Ridrodinchengchitnopn\n",
      "Briteator\n",
      "Yrinotosaurus\n",
      "Pciosaurus\n",
      "Ondocrratopr\n",
      "Arolligosaurus\n",
      "\n",
      "\n",
      "Iteration: 28000, Loss: 23.070858\n",
      "\n",
      "Brunitfomamuahenisaurus\n",
      "Saqrantettalvabmonosaurus\n",
      "Ptasaurus\n",
      "Tlgasaurus\n",
      "Penosaurus\n",
      "Frisaurus\n",
      "Medanillipaliuchacaelichaadinyfagsacikenisaurus\n",
      "\n",
      "\n",
      "Iteration: 30000, Loss: 23.070858\n",
      "\n",
      "Mrgamocomatinoelathus\n",
      "Pulucurstripnisus\n",
      "Mimasteosaurus\n",
      "Chastosaurus\n",
      "Lroia\n",
      "Euacaerus\n",
      "Yuwamosaurus\n",
      "\n",
      "\n",
      "Iteration: 32000, Loss: 23.070858\n",
      "\n",
      "Yeuwichabeptorophourasaurus\n",
      "Grapucorluntenachyesauroinaenyx\n",
      "Chunosaurus\n",
      "Enisaurus\n",
      "Olosauriaurus\n",
      "Wuidosaurus\n",
      "Njchianciausaurus\n",
      "\n",
      "\n",
      "Iteration: 34000, Loss: 23.070858\n",
      "\n",
      "Kuerupberophisuchus\n",
      "Rixiaelaratttrvanitans\n",
      "Erophaidan\n",
      "Qleatara\n",
      "Plorecrnitholephale\n",
      "Plosaurus\n",
      "Molita\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = model(data, ix_to_char, char_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
